Test for Individual Differences
*********
Lesson
================

.. article-info::
    :avatar: UCLA_Suit.jpg
    :avatar-link: https://www.decisionneurosciencelab.com/elijahgalvan
    :author: Elijah Galvan
    :date: September 1, 2023
    :read-time: 12 min read
    :class-container: sd-p-2 sd-outline-muted sd-rounded-1

Goal During this Stage
---------------

We want to explicitly test whether or not people are different from each other, or if our findings indicate a tendency that is true of all people in the same way. 

How to Achieve this Goal
------------

.. dropdown:: Embodying No Individual Differences

    .. tab-set::

        .. tab-item:: Plain English

            We've already identified the best model and now we want to see if the instance that we proved was best - where we estimated :bdg-success:`Free Parameters` for each :bdg-success:`Subjects` - was justified in its complexity. 
            Even if our best model captures 'individual differences' - i.e. multiple potential strategies - it does not necessarily mean that :bdg-success:`Subjects` are different. 
            Instead it indicates that this multinorm model is able to capture behavior that is not explained by any simplification of it. 
            Testing for individual differences invovles training an instance of our model over data where we do not differentiate between :bdg-success:`Subjects` and we then compare this model's performance to a 

        .. tab-item:: R

            :: 

                obj_function_nid = function(params, df, method = "OLS") {
                    Parameter1 = params[1]
                    Parameter2 = params[2]

                    decisions = df$Decision

                    predicted_utility = vector('numeric', length(df[,1]))
                    observed_utility = vector('numeric', length(df[,1]))
                    for (k in 1:length(df[,1])){
                        IV = df[k, 1]
                        Constant = df[k, 2]
                        Choices = #

                        Utility = vector('numeric', length(Choices))
                        for (n in 1:length(Choices)){
                            Utility[n] = utility(Parameter1, Parameter2,
                                                construct1(IV, Constant, Choices[n]),
                                                construct2(IV, Constant, Choices[n]),
                                                construct3(IV, Constant, Choices[n]))
                        }
                        predicted_utility[k] = max(Utility)
                        observed_utility[k] = Utility[k]
                    }
                    if (method == "OLS"){
                        return(sum((predicted_utility - observed_utility)**2))
                    } else if (method == "MLE"){
                        return(-1 * sum(dnorm(observed_utility, mean = predicted_utility, sd = sd, log = TRUE)))
                    }
                }

                result = fmincon(obj_function_nid,x0 = initial_params, A = NULL, b = NULL, Aeq = NULL, beq = NULL,
                                 lb = lower_bounds, ub = upper_bounds,
                                 df = trailData)

                trialData$PredictedNID = vector('numeric', length(trialData$SubjectID))
                for (i in 1:length(trialData$IV)){
                    Utility = vector('numeric', length(Choices))
                    for (j in 1:length(Choices)){
                        Utility[j] = utility(parameter1 = results$par[1],
                                             parameter2 = results$par[2],
                                             construct1 = construct1(trialData$IV[k], trialData$Constant[k], Choices[n]),
                                             construct2 = construct2(trialData$IV[k], trialData$Constant[k], Choices[n])),
                                             construct3 = construct3(trialData$IV[k], trialData$Constant[k], Choices[n])
                    }
                    trialData$PredictedNID[i] = Choices[which(Utility == max(Utility))]
                }

                subjectData$SS_NID = vector('numeric', length(trialData$SubjectID))
                for (i in 1:length(subjectData$SubjectID)){
                    trials = which(subjectData$SubjectID[i] == trialData$SubjectID)
                    subjectData$SS_NID[i] = sum((trialData$Decision - trialData$PredictedNID)**2)
                }

                # number of parameter divided by the number of people (i.e. number of parameters for each person)
                subjectData$AIC_NID = length(trialList$IV) * log(subjectData$SS_NID/length(trialList$IV)) + 2 * (2/length(subjectData$SubjectID)) 

                t.test(subjectData$AIC_NID, subjectData$model_AIC, paired = T)

        .. tab-item:: MatLab

            ::

                function result = obj_function_nid(params, df, method)
                    Parameter1 = params(1);
                    Parameter2 = params(2);

                    decisions = df.Decision;

                    predicted_utility = zeros(length(df), 1);
                    observed_utility = zeros(length(df), 1);
                    
                    for k = 1:length(df)
                        IV = df(k, 1);
                        Constant = df(k, 2);
                        Choices = [];  % You need to define Choices here
                        
                        Utility = zeros(length(Choices), 1);
                        for n = 1:length(Choices)
                            Utility(n) = utility(Parameter1, Parameter2, ...
                                construct1(IV, Constant, Choices(n)), ...
                                construct2(IV, Constant, Choices(n)), ...
                                construct3(IV, Constant, Choices(n)));
                        end
                        predicted_utility(k) = max(Utility);
                        observed_utility(k) = Utility(k);
                    end
                    
                    if strcmp(method, 'OLS')
                        result = sum((predicted_utility - observed_utility).^2);
                    elseif strcmp(method, 'MLE')
                        result = -1 * sum(log(normpdf(observed_utility, predicted_utility, sd)));
                    end
                end

                options = optimoptions('fmincon', 'Algorithm', 'interior-point');
                result = fmincon(@(params) obj_function_nid(params, trailData, 'OLS'), initial_params, [], [], [], [], lower_bounds, upper_bounds, [], options);

                trialData.PredictedNID = zeros(length(trialData.SubjectID), 1);
                for i = 1:length(trialData.IV)
                    Utility = zeros(length(Choices), 1);
                    for j = 1:length(Choices)
                        Utility(j) = utility(result(1), result(2), ...
                            construct1(trialData.IV(i), trialData.Constant(i), Choices(j)), ...
                            construct2(trialData.IV(i), trialData.Constant(i), Choices(j)), ...
                            construct3(trialData.IV(i), trialData.Constant(i), Choices(j)));
                    end
                    [~, idx] = max(Utility);
                    trialData.PredictedNID(i) = Choices(idx);
                end

                subjectData.SS_NID = zeros(length(subjectData.SubjectID), 1);
                for i = 1:length(subjectData.SubjectID)
                    trials = find(subjectData.SubjectID(i) == trialData.SubjectID);
                    subjectData.SS_NID(i) = sum((trialData.Decision(trials) - trialData.PredictedNID(trials)).^2);
                end

                subjectData.AIC_NID = length(trialList.IV) * log(subjectData.SS_NID / length(trialList.IV)) + 2 * (2 / length(subjectData.SubjectID));

                ttest(subjectData.AIC_NID, subjectData.model_AIC, 'paired');

        .. tab-item:: Python
            
            ::

                def obj_function_nid(params, df, method):
                    Parameter1 = params[0]
                    Parameter2 = params[1]

                    decisions = df['Decision'].values

                    predicted_utility = np.zeros(len(df))
                    observed_utility = np.zeros(len(df))

                    for k in range(len(df)):
                        IV = df.iloc[k, 0]
                        Constant = df.iloc[k, 1]
                        Choices = []  # Define Choices here

                        Utility = np.zeros(len(Choices))
                        for n in range(len(Choices)):
                            Utility[n] = utility(Parameter1, Parameter2,
                                                construct1(IV, Constant, Choices[n]),
                                                construct2(IV, Constant, Choices[n]),
                                                construct3(IV, Constant, Choices[n]))
                        predicted_utility[k] = np.max(Utility)
                        observed_utility[k] = Utility[k]

                    if method == 'OLS':
                        return np.sum((predicted_utility - observed_utility) ** 2)
                    elif method == 'MLE':
                        return -1 * np.sum(np.log(norm.pdf(observed_utility, loc=predicted_utility, scale=sd)))

                result = minimize(lambda params: obj_function_nid(params, trailData, 'OLS'), initial_params, bounds=list(zip(lower_bounds, upper_bounds)))

                trialData['PredictedNID'] = np.zeros(len(trialData['SubjectID']))
                for i in range(len(trialData['IV'])):
                    Utility = np.zeros(len(Choices))
                    for j in range(len(Choices)):
                        Utility[j] = utility(result.x[0], result.x[1],
                                            construct1(trialData['IV'].iloc[i], trialData['Constant'].iloc[i], Choices[j]),
                                            construct2(trialData['IV'].iloc[i], trialData['Constant'].iloc[i], Choices[j]),
                                            construct3(trialData['IV'].iloc[i], trialData['Constant'].iloc[i], Choices[j]))
                    trialData['PredictedNID'].iloc[i] = Choices[np.argmax(Utility)]

                subjectData['SS_NID'] = np.zeros(len(subjectData['SubjectID']))
                for i in range(len(subjectData['SubjectID'])):
                    trials = np.where(subjectData['SubjectID'].iloc[i] == trialData['SubjectID'])[0]
                    subjectData['SS_NID'].iloc[i] = np.sum((trialData['Decision'].iloc[trials] - trialData['PredictedNID'].iloc[trials]) ** 2)

                subjectData['AIC_NID'] = len(trialList['IV']) * np.log(subjectData['SS_NID'] / len(trialList['IV'])) + 2 * (2 / len(subjectData['SubjectID']))

                ttest_rel(subjectData['AIC_NID'], subjectData['model_AIC'])

Tutorials
==========

Tutorial 1 - van Baar, Chang, & Sanfey, 2019
----------------------

.. dropdown:: Embodying No Individual Differences

    .. tab-set::

        .. tab-item:: R

            ::

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

Tutorial 2 - Galvan & Sanfey, 2024
-------------------

.. dropdown:: Embodying No Individual Differences

    .. tab-set::

        .. tab-item:: R

            ::

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

Tutorial 3 - Crockett et al., 2014
-------------------

.. dropdown:: Embodying No Individual Differences

    .. tab-set::

        .. tab-item:: R

            ::

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::