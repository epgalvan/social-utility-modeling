Simulating Data
*********

Lesson
================

.. article-info::
    :avatar: UCLA_Suit.jpg
    :avatar-link: https://www.decisionneurosciencelab.com/elijahgalvan
    :author: Elijah Galvan
    :date: September 1, 2023
    :read-time: 15 min read
    :class-container: sd-p-2 sd-outline-muted sd-rounded-1

Goal During this Stage
---------------

Now we want to plug in all of the inputs that we know (experimental variables and free parameters) into the data generation process (the computational model) and see what it outputs.

.. dropdown:: Visualizing this Process

    .. figure:: comp_modeling.gif
        :figwidth: 100%
        :align: center

    Seems easy enough right? 

.. dropdown:: Choosing a Programming Language

    .. Note:: 

        Here, the path taken by MatLab will diverge slightly. 
        In comparison with R - which is designed around long format data frames, MatLab is designed around the Matrix. 
        For beginners with access to MatLab and no particular preference about programming language, I would recommend using MatLab. 
        The idea is aligned with the above illustration: each coordinate has a cell in a structure and the contents of the cell are a structure with various fields. 
        So, in essence, where we are essentially saying that each coordinate represents one hypothetical person this means that each cell represents a hypothetical person: 
        we can open the structure in the cell and look at the fields which tell us something about that hypothetical person - their parameter values (together telling us their coordinates in parameter space) and the decisions that they would make.
        
        I chose to keep Python in long format just like R - Python is less concise than either MatLab or R so, to reduce the amount of code to keep track of, this was preferable. 
        Nonethless, I think it is still possible to easily switch by translating the MatLab code to Python with ChatGPT.

.. Note:: **Modeling Binary vs. Continuous Choice Tasks**

    We always assume (and with good reason, in the case of these tasks) that the distribution of :bdg-danger:`Decisions` is normal. 
    Now, even if we don't give them the option to return a fraction of a token - meaning we have an interval, rather than a continuous scale - common statistical practice is to treat it as continuous, rather than categorical. 
    In other words, if our model predicts 10 tokens and the :bdg-success:`Subject` actually chooses 12, our error in prediction is better specified as 2 tokens rather than just **WRONG**. 
    Continuous (or interval) choice tasks aim to elicit :bdg-danger:`Decisions` which indicate the average, modal response in a given situation (i.e. the central tendency). 
    Consequently, since 1) our model predicts the central tendency, 2) the distribution around this tendency is normal (an assumption that we'll check later), and 3) our :bdg-success:`Free Parameter` recovery process 
    is based on the normaility of this distribution (depending on the estimator we use) we don't need to explicitly model this probability distribution. 

    .. figure:: 1_6_continuous.png
        :figwidth: 100%
        :align: center

    In contrast, consider a binary choice. 
    If we assume that the distribution of these choices is normal, this means something slightly different: using the above picture, let's imagine a scenario where our :bdg-success:`Subject` has a choice between 10 tokens and 12 tokens. 
    We need to draw a line between these different :bdg-danger:`Decisions` - let's draw this right between 10 and 12 at 11. 
    Here, we can say that 84% of the time (the proportion of the area under this curve which is left of 11 tokens) this :bdg-success:`Subject` will choose the 10 token option and that 16% of the time they'll choose the 12 token option. 
    In other words, if we give this :bdg-success:`Subject` the exact same choice between 10 tokens and 12 tokens 100 times, we would expect that - on average - they would choose 10 tokens 86 times and 12 tokens 14 times. 

    .. figure:: 1_6_discrete.png
        :figwidth: 100%
        :align: center
    
    Obviously, this is entirely out of the question - :bdg-success:`Subjects` will disengage after seeing the exact same :bdg-primary:`Trial` and having to make the same :bdg-danger:`Decision` after 10 or 20 times, much less 100 times. 
    Thus, the only realistic solution is to actually model this probabilistic, noisy :bdg-danger:`Decision` process - characterizing how random or noisy this process is. 
    Here, the model will aim to characterize how probable the :bdg-success:`Subject` is to make either possible :bdg-danger:`Decision`. 
    In this way, you are essentially **hedging your model's bets**  which thereby enables your model to overcome sampling error, identifying the central tendency by preventing overcorrection for stochasticity. 

    Revisiting the above example, if the :bdg-success:`Subject` chooses the 12 tokens, what is our model error?

    A. 12- 10 = 2 tokens
    B. Wrong Answer = 1 (Binary)
    C. 1 - Area Left of midpoint between 12 and 10 tokens = 0.84

    .. dropdown:: Answer

        If our model is capturing the noisy, probabilistic nature of decision-making in a binary choice task (which it should, particularly when you don't have an exorbitant amount of :bdg-primary:`Trials` ), our :bdg-success:`Free Parameters`
        should minimize the probability that our model makes incorrect predictions. 
        Thus, while technically all three *could* be considered correct, the best answer is 'C'. 

    Now, as we'll see, we're going to recover :bdg-success:`Free Parameters` from :bdg-danger:`Decisions` by recursively trying different :bdg-success:`Free Parameters` , settling on whichever one minimizes the difference betweeen expected 
    :bdg-warning:`Utility` (based on predicted :bdg-danger:`Decisions` for a set of :bdg-success:`Free Parameters` ) and observed :bdg-warning:`Utility` (based on this same set of :bdg-success:`Free Parameters` and observed :bdg-danger:`Decisions` ). 
    For binary choice tasks, there is an additonal step - using the difference in :bdg-warning:`Utility` between options to characterize how probable each choice is to be selected
    (given :bdg-success:`Free Parameters` which characterize how stochastic or random the :bdg-danger:`Decisions` a given :bdg-success:`Subject` makes are). 
    
    .. figure:: 1_6_discrete_utility.png
        :figwidth: 100%
        :align: center

    The way we do this is the following, often referred to as a softmax function. 
    Here :bdg-warning:`Utility Difference` is referred to as ``DU``

    ::

        Probability | DU =  (1)/(1 + e ** (-1 * gamma * DU))

    .. figure:: 1_6_softmax.png
        :figwidth: 100%
        :align: center

    Sometimes, a further noise parameter is added to capture attention deficits (i.e. not changing to the alternative solely because one's attention waxes and wanes.)

    ::

        Probability | DU =  ((1)/(1 + e ** (-1 * gamma * DU))) * (1 - (2 * epsilon)) + epsilon

How to Achieve this Goal
------------    

.. dropdown:: Preallocating, Defining Functions, Defining Trial List, and Defining Parameters

    .. tab-set::

        .. tab-item:: Plain English

            Before you start simulating data, you need to check off a pretty simple list: 

                1. Define the Trial List

                * Define the value of all :bdg-primary:`Independant Variables` and all relevant :bdg-primary:`Constants` (and all possible :bdg-danger:`Decisions` if these do not change from trial-to-trial)

                2. Define Your Functions

                * Define the value of all :bdg-secondary:`Construct Value` functions and the :bdg-warning:`Utility` function

                3. Define Your Parameters

                * Define the range and resolution of each of your :bdg-success:`Free Parameters`

                4. Preallocate Model Output

                * Preallocate the data storage structures for the model-predicted :bdg-danger:`Decisions` for each Trial, for each Coordinate (i.e. pair of :bdg-success:`Free Parameters`)

        .. tab-item:: R

            ::

                trialList = data.frame(IV = vector(), Constant = vector())

                # choices = vector()

                utility = function(construct1, construct2, construct3, parameter1, parameter2){
                    return(utility)
                }

                freeParameters = data.frame(parameter1 = vector(), 
                                            parameter2 = vector())

                predictions = data.frame()

        .. tab-item:: MatLab

            ::

                trialList = table([], [], 'VariableNames', {'IndependantVariable', 'Constant'});

                % choice

                function value = construct1(iv, constant, choice)
                    value = construct_value;
                end

                function value = construct2(iv, constant, choice)
                    value = construct_value;
                end

                function value = construct3(iv, constant, choice)
                    value = construct_value;
                end

                function value = utility(construct1, construct2, construct3, parameter1, parameter2)
                    value = utility;
                end

                parameter1range = [];
                parameter2range = [];

                freeParameters = struct('parameter1', {}, 'parameter2', {}, 'predictions', {});
                for i = 1:numel(parameter1range)
                    for j = 1:numel(parameter2range)
                        freeParameters(i, j).parameter1 = parameter1range(i);
                        freeParameters(i, j).parameter2 = parameter2range(j);
                        freeParameters(i, j).predictions = zeros(size(triaList, 1), 1); 
                    end
                end


        .. tab-item:: Python

            :: 

                import pandas as pd
                import numpy as np

                trialList = pd.DataFrame({
                    'IndependantVariable': [],
                    'Constants': [],
                })

                # choices = []

                def construct1(iv, constant, choice):
                    return(construct_value)
                
                def construct2(iv, constant, choice):
                    return(construct_value)

                def construct3(iv, constant, choice):
                    return(construct_value)

                def utility(constructs, parameters):
                    return(utility)

                freeParameters = pd.DataFrame({
                    'parameter1': [],
                    'parameter2': []
                })

                predictions = pd.DataFrame()
    

.. dropdown:: Define the :bdg-success:`Free Parameter` Loop

    .. tab-set::

        .. tab-item:: Plain English

            We're going to start our most superior ``for`` loop which iterates over unique combinations of :bdg-success:`Free Parameters`. 

            Each combination of :bdg-success:`Free Parameters` can be thought of as a hypothetical person. 
            In the context of our model, :bdg-success:`Free Parameters` mathematically represent the conceptual dimensions which characterize **all** of the ways that people can be different in your experimental paradigm. 
            Thus, we are generating predictions about what any given person (i.e. a certain coordinate in our parameter space) *would* do in our experiment *if* it is indeed true that our equation aptly represents the data generation process. 

            .. dropdown:: So what are we starting with in this loop? 
                
                :bdg-success:`Free Parameters` 

            .. dropdown:: And what do we want to finish this loop with?

                :bdg-danger:`Decisions` for all of the :bdg-primary:`Trials` in our set. 

            .. dropdown:: So what do we need to preallocate before this loop starts?

                An output for the predicted :bdg-danger:`Decisions`. We already did this above, nice. 

            .. dropdown:: Then, what do we need to compute within this loop?

                We need to determine what the predicted :bdg-danger:`Decisions` for all of the :bdg-primary:`Trials` in our set are for those :bdg-success:`Free Parameters`
            

        .. tab-item:: R

            ::
                
                for (i in 1:length(freeParameters[,1])){
                    parameter1 = freeParameters[i,1]
                    parameter2 = freeParameters[i,2]
                    
                    #Compute Predictions
                    predictions[i,] = #To Compute
                }


        .. tab-item:: MatLab

            ::

                for i = 1:numel(parameter1range)
                    for j = 1:numel(parameter2range)
                        Parameter1 = freeParameters(i,j).parameter1
                        Parameter2 = freeParameters(i,j).parameter2

                        %Compute Predictions
                        freeParameters(i,j).predictions = %toCompute
                    end
                end


        .. tab-item:: Python

            :: 

                for i in range(len(freeParameters)):
                    Parameter1 = freeParameters[i, 0]
                    Parameter2 = freeParameters[i, 1]

                    # Compute Predictions
                    predictions[i, :] = # To Compute

.. dropdown:: Define the :bdg-primary:`Trial` Loop

    .. tab-set::

        .. tab-item:: Plain English

            Now, we are going to begin answering the Compute Predictions demand placed on us in the :bdg-success:`Free Parameter` Loop. 
            So we're within the :bdg-success:`Free Parameter` Loop and thus we have our :bdg-success:`Free Parameter` values defined - so let's say that theoretically we're adopting the perspective of one hypothetical person. 
            What we want to answer specifically is "What should this hypothetical person do on this particular :bdg-primary:`Trial`?".


            .. dropdown:: So what are we starting with in this loop? 

                We're starting with the :bdg-primary:`Independent Variables`, :bdg-primary:`Constants`, and possible :bdg-danger:`Decisions` at the start of each :bdg-primary:`Trial`. 

                We already have :bdg-success:`Free Parameters` defined. 

            .. dropdown:: And what do we want to finish this loop with?

                The predicted :bdg-danger:`Decision` for this :bdg-primary:`Trial`. 

            .. dropdown:: So what do we need to preallocate before this loop starts?

                We need to preallocate a vector for all :bdg-danger:`Decisions` for this coordinate pair. 
                However, we already have a preallocated data structure, so for simplicity sake we'll move that within the :bdg-primary:`Trial` loop - defining the model prediction directly on a trial-by-trial basis rather than a coordinate-by-coordinate basis. 

            .. dropdown:: Then, what do we need to compute within this loop?

                We need to compute the :bdg-warning:`Utility` for all possible :bdg-danger:`Decisions` in this :bdg-primary:`Trial`. 
                Then, we need to save the :bdg-danger:`Decision` which results in the greatest :bdg-warning:`Utility`.

        .. tab-item:: R

            ::

                for (i in 1:length(freeParameters[,1])){
                    Parameter1 = freeParameters[i,1]
                    Parameter2 = freeParameters[i,2]
                    
                    #Just Added
                    for (k in 1:length(trialList[,1])){
                        IV = trialList[k, 1]
                        Constant = trialList[k, 2]
                        #Choices = vector() #if not already defined
                        
                        # Compute Utility 
                        
                        predictions[i,k] = # To Compute
                    }
                }

        .. tab-item:: MatLab

            ::
                
                for i = 1:numel(thetaRange)
                    for j = 1:numel(phiRange)
                        Parameter1 = freeParameters(i,j).parameter1
                        Parameter2 = freeParameters(i,j).parameter2

                        %Just Added
                        for k = 1:height(trialList(:,1))
                            IV = trialList{k,1};
                            Constant = trialList{k,2};
                            %Choices = []; %if not already defined

                            % Compute Utility

                            freeParameters(i,j).predictions(k) = %toCompute
                        end
                    end
                end

        .. tab-item:: Python

            ::

                for i in range(len(freeParameters)):
                    Parameter1 = freeParameters[i, 0]
                    Parameter2 = freeParameters[i, 1]
                    
                    #Just Added
                    for k in range(len(trialList)):
                        IV = trialList[k, 0]
                        Constant = trialList[k, 1]                        
                        #Choices = [] #if not already defined

                        # Compute Utility
                        
                        predictions[i, k] = # To Compute


.. dropdown:: Define the :bdg-danger:`Decision` Loop

        .. tab-set::

            .. tab-item:: Plain English

                    We're going to start our most inferior ``for`` loop which iterates over all possible :bdg-danger:`Decisions`. 

                    Here, we're going to answer the Compute Utility demand placed on us in the :bdg-primary:`Trial` loop.

                    .. dropdown:: So what are we starting with in this loop? 
                        
                        We're starting with one of the possible :bdg-success:`Decisions` at the start of each loop. 

                        We already have :bdg-primary:`Independent Variables`, :bdg-primary:`Constants`, and possible :bdg-danger:`Decisions` defined at the start of the :bdg-primary:`Trial` loop and 

                        :bdg-success:`Free Parameters` defined at the start of the :bdg-success:`Free Parameter` loop. 

                    .. dropdown:: And what do we want to finish this loop with?

                        The :bdg-warning:`Utility` which would be derived for all :bdg-danger:`Decisions` on this :bdg-primary:`Trial`. 

                    .. dropdown:: So what do we need to preallocate before this loop starts?

                        A vector for :bdg-warning:`Utility` which has the same length as all possible :bdg-danger:`Decisions`. 
                        
                        Also, let's remember that it's possible that multiple :bdg-danger:`Decisions` will maximize utility. 
                        Therefore, let's make sure that our script doesn't error by potentially outputting multiple :bdg-danger:`Decisions` predictions - we'll randomly select between whichever maximizes utility. 
                        Let's also output a vector which keeps track of the number of :bdg-primary:`Trials` where multiple :bdg-danger:`Decisions` maximize :bdg-warning:`Utility` (i.e. our model makes non-specific predictions) for each pair of :bdg-success:`Free Parameters`. 
                        A few of :bdg-primary:`Trials` for a few :bdg-success:`Free Parameters` is acceptable, but let's just keep an eye on it. 

                    .. dropdown:: Then, what do we need to compute within this loop?

                        Nothing, this is the smallest loop. We're ready to get our answer.
            
            .. tab-item:: R

                ::

                    non_specific = rep(0, length(freeParameters[,1])) # Just Added This Line
                    
                    for (i in 1:length(freeParameters[,1])){
                        Parameter1 = freeParameters[i,1]
                        Parameter2 = freeParameters[i,2]                    
                        for (k in 1:length(trialList[,1])){
                            IV = trialList[k, 1]
                            Constant = trialList[k, 2]
                            #Choices = vector() #if not already defined
                            
                            # Just Added
                            Utility = vector('numeric', length(Choices))
                            for (n in 1:length(Choices)){
                                Utility[n] = utility(parameter1 = Parameter1,
                                                    parameter2 = Parameter2,
                                                    construct1 = construct1(IV, Constant, Choices[n]),
                                                    construct2 = construct2(IV, Constant, Choices[n]),
                                                    construct3 = construct3(IV, Constant, Choices[n]))
                            }
                            correct_choice = which(Utility == max(Utility))
                            if (length(correct_choice) > 1){
                                correct_choice = correct_choice[sample(correct_choice, 1)]
                                non_specific[i] =+ 1
                            }
                            predictions[i,k] = Choices[correct_choice]
                        }
                    }
                    
            .. tab-item:: MatLab

                ::
                
                    freeParameters = struct('theta', {}, 'phi', {}, 'predictions', {}, 'non_specific', {}); %Just Changed This Line

                    for i = 1:numel(thetaRange)
                        for j = 1:numel(phiRange)
                            Parameter1 = freeParameters(i,j).parameter1
                            Parameter2 = freeParameters(i,j).parameter2

                            %Just Added
                            for k = 1:height(trialList(:,1))
                                IV = trialList{k,1};
                                Constant = trialList{k,2};
                                %Choices = []; %if not already defined

                                % Just Added
                                Utility = zeros(size(Choices));
                                for n = 1:height(Choices(:,1))
                                    Utility(n) = utility(parameter1 = Parameter1,
                                                        parameter2 = Parameter2,
                                                        construct1 = construct1(IV, Constant, Choices[n]),
                                                        construct2 = construct2(IV, Constant, Choices[n]),
                                                        construct3 = construct3(IV, Constant, Choices[n]))
                                end
                                correct_choice = find(Utility == max(Utility));
                                if numel(correct_choice) > 1
                                    correct_choice = correct_choice(randi(numel(correct_choice)));
                                    freeParameters(i,j).non_specific(k) = freeParameters(i,j).non_specific(k) + 1;
                                end
                                freeParameters(i,j).predictions(k) = Choices(correct_choice)
                            end
                        end
                    end

                    
            .. tab-item:: Python

                ::

                    non_specific = [0] * len(freeParameters) # Just Added this Line 

                    for i in range(len(freeParameters)):
                        Parameter1 = freeParameters[i, 0]
                        Parameter2 = freeParameters[i, 1]
                        
                        for k in range(len(trialList)):
                            IV = trialList[k, 0]
                            Constant = trialList[k, 1]                        
                            #Choices = [] #if not already defined

                            #Just Added
                            Utility = [0] * len(Choices)
                            for n in range(len(Choices)):
                                Utility[n] = utility(parameter1 = Parameter1,
                                                    parameter2 = Parameter2,
                                                    construct1 = construct1(IV, Constant, Choices[n]),
                                                    construct2 = construct2(IV, Constant, Choices[n]),
                                                    construct3 = construct3(IV, Constant, Choices[n]))
                            
                            correct_choice = [idx for idx, val in enumerate(Utility) if val == max(Utility)]
                            if len(correct_choice) > 1:
                                correct_choice = random.sample(correct_choice, 1)
                                non_specific[i] += 1

                            predictions[i, k] = Choices[correct_choice[0]]



Tutorials
================

Tutorial 1 - van Baar, Chang, & Sanfey, 2019
-------------------

.. dropdown:: Preallocating, Defining Functions, Defining Trial List, and Defining Parameters

        .. tab-set::

            .. tab-item:: R

                ::

                    #Construct Value Formulations Above this
                    trialList = data.frame(Investment = rep(seq(1, 10, 1), times = 6),
                                           Multiplier = rep(c(2, 4, 6), each = 20),
                                           Believed_Multiplier = rep(4, 60),
                                           Endowment = rep(10, 60))

                    utility = function(theta, phi, guilt, inequity, payout){
                        return(theta*payout - (1-theta)*min(guilt + phi, inequity - phi))
                    }

                    freeParameters = data.frame(theta = rep(seq(0, 0.5, 0.005), each = 101), 
                                                phi = rep(seq(-0.1, 0.1, 0.002), times = 101))

                    predictions = data.frame()

            .. tab-item:: MatLab

                ::

                    trialList = table(repelem(1:10, 8)', repmat([2; 4; 4; 6], 20, 1), repmat(4, 80, 1), repmat(10, 80, 1), 'VariableNames', {'Investment', 'Multiplier', 'Believed_Multiplier', 'Endowment'});

                    function value = payout_maximization(investment, multiplier, returned)
                        value = ((investment * multiplier) - returned) / (investment * multiplier);
                    end

                    function value = inequity(investment, multiplier, returned, endowment)
                        value = ((investment * multiplier - returned)/(investment * multiplier + endowment - investment))^2;
                    end

                    function value = guilt(investment, believed_multiplier, returned, multiplier)
                        value = ((investment * believed_multiplier)/2 - returned) / (investment * multiplier);
                    end

                    function value = utility(theta, phi, guilt, inequity, payout)
                        value = (theta*payout - (1-theta)*min(guilt + phi, inequity - phi));
                    end

                    thetaRange = 0:0.005:0.5;
                    phiRange = -0.1:0.002:0.1;

                    freeParameters = struct('theta', {}, 'phi', {}, 'predictions', {});
                    for i = 1:numel(thetaRange)
                        for j = 1:numel(phiRange)
                            freeParameters(i, j).theta = thetaRange(i);
                            freeParameters(i, j).phi = phiRange(j);
                            freeParameters(i, j).predictions = zeros(80, 1); % Empty vector of length 80
                        end
                    end


            .. tab-item:: Python

                :: 

                    import pandas as pd
                    import numpy as np

                    Investment = np.repeat(np.arange(1, 11), repeats=6)
                    Multiplier = np.repeat([2, 4, 6], repeats=20)
                    Believed_Multiplier = np.repeat(4, 60)
                    Endowment = np.repeat(10, 60)

                    trialList = pd.DataFrame({
                        'Investment': Investment,
                        'Multiplier': Multiplier,
                        'Believed_Multiplier': Believed_Multiplier,
                        'Endowment': Endowment
                    })

                    def payout_maximization(investment, multiplier, returned):
                        return ((investment * multiplier - returned) / (investment * multiplier))
                        
                    def inequity(investment, multiplier, returned, endowment):
                        return ((investment * multiplier - returned) / (investment * multiplier + endowment - investment)) ** 2
                        
                    def guilt(investment, believed_multiplier, returned, multiplier):
                        return ((investment * believed_multiplier / 2 - returned) / (investment * multiplier))

                    def utility(theta, phi, guilt, inequity, payout){
                        return(theta*payout - (1-theta)*min(guilt + phi, inequity - phi))
                    }
                        
                    theta = np.repeat(np.arange(0, 0.505, 0.005), repeats=101)
                    phi = np.tile(np.arange(-0.1, 0.102, 0.002), 101)

                    freeParameters = pd.DataFrame({
                        'theta': theta,
                        'phi': phi
                    })

                    predictions = pd.DataFrame()

.. dropdown:: Define the :bdg-success:`Free Parameter` Loop

    .. tab-set::

        .. tab-item:: R

            ::
                
                for (i in 1:length(freeParameters[,1])){
                    Theta = freeParameters[i,1]
                    Phi = freeParameters[i,2]
                    
                    #Compute Predictions
                    predictions[i,] = #To Compute
                }


        .. tab-item:: MatLab

            ::
                
                for i = 1:numel(thetaRange)
                    for j = 1:numel(phiRange)
                        Theta = freeParameters(i,j).theta
                        Phi = freeParameters(i,j).phi

                        %Compute Predictions
                        freeParameters(i,j).predictions = %toCompute
                    end
                end


        .. tab-item:: Python

            :: 

                for i in range(len(freeParameters)):
                    Theta = freeParameters[i, 0]
                    Phi = freeParameters[i, 1]

                    # Compute Predictions
                    predictions[i, :] = # To Compute

.. dropdown:: Define the :bdg-primary:`Trial` Loop

    .. tab-set::

        .. tab-item:: R

            ::

                for (i in 1:length(freeParameters[,1])){
                    Theta = freeParameters[i,1]
                    Phi = freeParameters[i,2]
                    
                    #Just Added
                    for (k in 1:length(trialList[,1])){
                        I = trialList[k, 1]
                        M = trialList[k, 2]
                        B = trialList[k, 3]
                        E = trialList[k, 4]
                        Choices = seq(0, (I * M), 1)
                        
                        # Compute Utility 
                        
                        predictions[i,k] = # To Compute
                    }
                }

        .. tab-item:: MatLab

            ::
                
                for i = 1:numel(thetaRange)
                    for j = 1:numel(phiRange)
                        Theta = freeParameters(i,j).theta
                        Phi = freeParameters(i,j).phi
                    
                    %Just Added
                        for k = 1:height(trialList(:,1))
                            I = trialList{k,1};
                            M = trialList{k,2};
                            B = trialList{k,3};
                            E = trialList{k,4};
                            Choices = 0:1:(I*M);

                            % Compute Utility

                            freeParameters(i,j).predictions(k) = %toCompute
                        end
                    end
                end

        .. tab-item:: Python

            ::

                for i in range(len(freeParameters)):
                    Theta = freeParameters[i, 0]
                    Phi = freeParameters[i, 1]
                    
                    #Just Added
                    for k in range(len(trialList)):
                        I = trialList[k, 0]
                        M = trialList[k, 1]
                        B = trialList[k, 2]
                        E = trialList[k, 3]
                        Choices = list(range(0, I * M + 1, 1))

                        # Compute Utility
                        
                        predictions[i, k] = # To Compute

.. dropdown:: Define the :bdg-danger:`Decision` Loop

        .. tab-set::
            
            .. tab-item:: R

                ::

                    non_specific = rep(0, length(freeParameters[,1])) # Just Added This Line
                    
                    for (i in 1:length(freeParameters[,1])){
                        Theta = freeParameters[i,1]
                        Phi = freeParameters[i,2]
                        
                        for (k in 1:length(trialList[,1])){
                            I = trialList[k, 1]
                            M = trialList[k, 2]
                            B = trialList[k, 3]
                            E = trialList[k, 4]
                            Choices = seq(0, (I * M), 1)
                            
                            # Just Added
                            Utility = vector('numeric', length(Choices))
                            for (n in 1:length(Choices)){
                                Utility[n] = utility(theta = Theta,
                                                    phi = Phi,
                                                    guilt = guilt(I, B, Choices[n], M),
                                                    inequity = inequity(I, M, Choices[n], E),
                                                    payout = payout_maximization(I, M, Choices[n]))
                            }
                            correct_choice = which(Utility == max(Utility))
                            if (length(correct_choice) > 1){
                                correct_choice = correct_choice[sample(1:length(correct_choice), 1)]
                                non_specific[i] =+ 1
                            }
                            predictions[i,k] = Choices[correct_choice]
                        }
                    }
                    
            .. tab-item:: MatLab

                ::
                
                    freeParameters = struct('theta', {}, 'phi', {}, 'predictions', {}, 'non_specific', {}); %Just Added this Line

                    for i = 1:numel(thetaRange)
                        for j = 1:numel(phiRange)
                            Theta = freeParameters(i,j).theta
                            Phi = freeParameters(i,j).phi
                            
                            for k = 1:height(trialList(:,1))
                                I = trialList{k,1};
                                M = trialList{k,2};
                                B = trialList{k,3};
                                E = trialList{k,4};
                                Choices = 0:1:(I*M);

                                %Just Added
                                Utility = zeros(size(Choices));
                                for n = 1:height(Choices(:,1))
                                    Utility(n) = utility(theta = Theta,
                                                         phi = Phi,
                                                         guilt = guilt(I, B, Choices(n), M),
                                                         inequity = inequity(I, M, Choices(n), E),
                                                         payout = payout_maximization(I, M, Choices(n)))
                                end
                                correct_choice = find(Utility == max(Utility));
                                if numel(correct_choice) > 1
                                    correct_choice = correct_choice(randi(numel([1:height(correct_choice)])));
                                    freeParameters(i,j).non_specific(k) = freeParameters(i,j).non_specific(k) + 1;
                                end
                                freeParameters(i,j).predictions(k) = Choices(correct_choice)
                            end
                        end
                    end

                    
            .. tab-item:: Python

                ::

                    non_specific = [0] * len(freeParameters) # Just Added this Line

                    for i in range(len(freeParameters)):
                        Theta = freeParameters[i, 0]
                        Phi = freeParameters[i, 1]

                        for k in range(len(trialList)):
                            I = trialList[k, 0]
                            M = trialList[k, 1]
                            B = trialList[k, 2]
                            E = trialList[k, 3]
                            Choices = list(range(0, I * M + 1, 1))

                            #Just Added
                            Utility = [0] * len(Choices)
                            for n in range(len(Choices)):
                                Utility[n] = utility(theta=Theta,
                                                    phi=Phi,
                                                    guilt=guilt(I, B, Choices[n], M),
                                                    inequity=inequity(I, M, Choices[n], E),
                                                    payout=payout_maximization(I, M, Choices[n]))
                            
                            correct_choice = [idx for idx, val in enumerate(Utility) if val == max(Utility)]
                            if len(correct_choice) > 1:
                                correct_choice = random.sample(range(len(correct_choice)), 1)
                                non_specific[i] += 1

                            predictions[i, k] = Choices[correct_choice[0]]

Tutorial 2 - Galvan & Sanfey, 2024
-------------------

.. dropdown:: Preallocating, Defining Functions, Defining Trial List, and Defining Parameters

    .. tab-set::

        .. tab-item:: R

            ::

                #first, create a noisy resource distribution that has gini between 0.3 and 0.4 where the maximum benefit or loss is approximately going to be 10 tokens
                shares = seq(0.05,0.95, 0.1)**1.25
                df = data.frame()
                for (k in 1:10){
                    df[1:20, k] = rnorm(20, mean=shares[k], sd=0.01*sum(shares))
                    df[which(df[,k] < 0),] = 0
                }

                #second, convert to a rounded percent
                for (k in 1:length(df[,1])) {
                    df[k,1:10] = round((df[k,1:10]/sum(df[k,1:10]))*100)
                }

                #third, ensure that there are exactly 100 tokens on each trial
                for (k in 1:length(df[,1])) {
                    if (sum(df[k,1:10]) < 100){
                        for (j in 1:(100-sum(df[k,1:10]))){
                        i = sample(1:10, 1)
                        df[k, i] = df[k, i] + 1
                        }
                    } 
                    if (sum(df[k,1:10]) > 100){
                        for (j in 1:(sum(df[k,1:10]) - 100)){
                        i = sample(which(df[k,1:10] > 0), 1)
                        df[k, i] = df[k, i] - 1
                        }
                    }
                }

                trialList = data.frame()

                #fourth, ensure that our subject is in each decile the same number of times
                for (k in 1:length(df[,1])){
                    i = round((k/2)+0.05) #because this function rounds down on even numbers and up on odd numbers
                    trialList[k, 1] = df[k, i]
                    intermediate = df[k, -i]
                    trialList[k, 2:10] = intermediate[1,sample(9)] #to insure that other players on screen are not all 
                }

                #trialList above
                choices = seq(0, 1, 0.1) #tax rate

                utility = function(theta, phi, Equity, Equality, Payout){
                    return((theta * Payout) + ((1 - theta) * ((phi * Equality) + ((1 - phi) * Equity))))
                }

                freeParameters = data.frame(theta = seq(0, 1, 0.01),
                                            phi = seq(0, 1, 0.01))

                predictions = data.frame()

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

.. dropdown:: Define the :bdg-success:`Free Parameter` Loop

    .. tab-set::

        .. tab-item:: R

            ::

                non_specific = rep(0, length(freeParameters[,1])) # Just Added This Line

                for (i in 1:length(freeParameters[,1])){
                    Theta = freeParameters[i,1]
                    Phi = freeParameters[i,2]

                    #Define Trials
                }

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

.. dropdown:: Define the :bdg-primary:`Trial` Loop

    .. tab-set::

        .. tab-item:: R

            ::

                non_specific = rep(0, length(freeParameters[,1])) # Just Added This Line

                for (i in 1:length(freeParameters[,1])){
                    Theta = freeParameters[i,1]
                    Phi = freeParameters[i,2]

                    #Just Added
                    for (k in 1:length(trialList[,1])){

                        #Determine Predicted Decisions
                    }
                }

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

.. dropdown:: Define the :bdg-danger:`Decision` Loop

    .. tab-set::

        .. tab-item:: R

            ::

                non_specific = rep(0, length(freeParameters[,1])) # Just Added This Line

                for (i in 1:length(freeParameters[,1])){
                    Theta = freeParameters[i,1]
                    Phi = freeParameters[i,2]
                    for (k in 1:length(trialList[,1])){

                        # Just Added
                        Utility = vector('numeric', length(choices))
                        for (n in 1:length(choices)){
                            Utility[n] = utility(theta = Theta,
                                                 phi = Phi,
                                                 Equity = equity(new_value(trialList[k, 1:10], choices[n]), trialList[k, 1:10], choices[n]),
                                                 Equality = equality(new_value(trialList[k, 1:10], choices[n]), trialList[k, 1:10], choices[n]),
                                                 Payout = payout(new_value(trialList[k, 1], choices[n]), trialList[k, 1], choices[n]))
                        }
                        correct_choice = which(Utility == max(Utility))
                        if (length(correct_choice) > 1){
                            correct_choice = correct_choice[sample(correct_choice, 1)]
                            non_specific[i] =+ 1
                        }
                        predictions[i,k] = Choices[correct_choice]
                    }
                }

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

Tutorial 3 - Crockett et al., 2014
-------------------

.. dropdown:: Preallocating, Defining Functions, Defining Trial List, and Defining Parameters

    .. tab-set::

        .. tab-item:: R

            ::

                trialList = data.frame(Default = rep(c(1, 2), each = 100),
                                       MoneyA = 10,
                                       MoneyB = rep(rep(seq(11, 20), each = 10), times = 2),
                                       ShocksA = rep(rep(seq(0, 9), times = 10), times = 2),
                                       ShocksB = 10)

                utility = function(Payout, Harm, kappa, lambda){
                    if (Payout < 0) {LM = lambda} else {LM = 1}
                    if (Harm > 0) {LS = lambda} else {LS = 1}
                    return((Payout * kappa * LM) - (Harm * (1 - kappa) * LS))
                }

                freeParameters = data.frame(kappa = rep(seq(0, 1, 0.1), 11), #ranging from 0 to 1, the inverse of kappa has the same range as kappa
                                            lambda = rep(seq(1, 3, 0.2), 11), #loss aversion is 2.25 according to CPT, 1 is no loss aversion
                                            gamma = sample(seq(0, 2, 0.01), 121), #completely random to low stochasticity
                                            epsilon = 0) #no additional, non-task related noise
                predictions = data.frame()

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

.. dropdown:: Define the :bdg-success:`Free Parameter` Loop

    .. tab-set::

        .. tab-item:: R

            ::

                for (i in 1:length(freeParameters[,1])){
                    Kappa = freeParameters[i,1]
                    Lambda = freeParameters[i,2]

                    #Define Trial Loop

                }

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

.. dropdown:: Define the :bdg-primary:`Trial` Loop

    .. tab-set::

        .. tab-item:: R

            ::

                for (i in 1:length(freeParameters[,1])){
                    Kappa = freeParameters[i,1]
                    Lambda = freeParameters[i,2]

                    #Just Added
                    for (k in 1:length(trialList[,1])){
                        shocksThis = c(trialList$ShocksA[k], trialList$ShocksB[k])[trialList$Default[k]]
                        shocksAlternative = c(trialList$ShocksB[k], trialList$ShocksA[k])[trialList$Default[k]]
                        moneyThis = c(trialList$MoneyA[k], trialList$MoneyB[k])[trialList$Default[k]]
                        moneyAlternative = c(trialList$MoneyB[k], trialList$MoneyA[k])[trialList$Default[k]]
                        
                        # Determine predictions

                    }
                }

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::

.. dropdown:: Determine the Predicted :bdg-danger:`Decision`

    .. tab-set::

        .. tab-item:: R

            ::

                for (i in 1:length(freeParameters[,1])){
                    Kappa = freeParameters[i,1]
                    Lambda = freeParameters[i,2]
                    for (k in 1:length(trialList[,1])){
                        shocksThis = c(trialList$ShocksA[k], trialList$ShocksB[k])[trialList$Default[k]]
                        shocksAlternative = c(trialList$ShocksB[k], trialList$ShocksA[k])[trialList$Default[k]]
                        moneyThis = c(trialList$MoneyA[k], trialList$MoneyB[k])[trialList$Default[k]]
                        moneyAlternative = c(trialList$MoneyB[k], trialList$MoneyA[k])[trialList$Default[k]]

                        # Just Added
                        Utility = utility(Payout = harm(shocksThis, shocksAlternative),
                                          Harm = payout(moneyThis, moneyAlternative),
                                          kappa = Kappa,
                                          lambda = Lambda)
                        if (Utility > 0) { 
                            predictions[i,k] = 1 #choose alternative
                        } else if (Utility < 0) {
                            predictions[i,k] = 0 #don't choose alternative
                        } else {
                            predictions[i,k] = sample(c(0, 1), 1) #random
                        }
                    }
                }

        .. tab-item:: MatLab

            ::

        .. tab-item:: Python

            ::