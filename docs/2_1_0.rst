Recovering Free Parameters
*************

Lesson
================

.. article-info::
    :avatar: UCLA_Suit.jpg
    :avatar-link: https://www.decisionneurosciencelab.com/elijahgalvan
    :author: Elijah Galvan
    :date: September 1, 2023
    :read-time: 11 min read
    :class-container: sd-p-2 sd-outline-muted sd-rounded-1

Goal During this Stage
---------------

Now that we have our data, our first objective is to determine what the :bdg-success:`Free Parameters` are for each :bdg-success:`Subject`. 

How to Achieve this Goal
------------

.. dropdown:: Preallocating and Defining Functions

    .. tab-set::

            .. tab-item:: Plain English

                Before we start recovering free parameters, we need to check off a pretty simple list. 
                There are several functions and variables that we should already have: in the event that you are using a seperate workspace from your simulation, make sure that these are included.

                1. :bdg-primary:`Trial` List - this should be in a certain order and have all of the trials that the subject has seen
                2. :bdg-secondary:`Construct Value` Functions - this should relate :bdg-danger:`Decisions`, :bdg-primary:`Independent Variables`, and :bdg-primary:`Constants` to a number which encapsulates how much :bdg-danger:`Decisions` violate/follow a relevant norm
                3. :bdg-warning:`Utility` Function - this should be a function of :bdg-secondary:`Construct Values` and :bdg-success:`Free Parameters`
                4. Your Objective Function - a function which takes :bdg-success:`Free Parameters` and :bdg-danger:`Decisions` and returns the error between Expected :bdg-warning:`Utility` and Observed :bdg-warning:`Utility`
                5. Optimizer Inputs - the Initial Parameters and Boundaries for your Objective Function

                Here, if we have a data set with subjects who are excluded, we need to know which subjects should be included in the analysis. 

                1. A list of all subject folders/files that tell us which data to retrieve for analysis - these must include the subject ID to be able to be identified

                We also need to preallocate the output of our analysis as well as the raw trial-by-trial data.

                1. A trial-level data structure
                2. A subject-level data structure

            .. tab-item:: R

                ::

                    all_subjects = read.csv2() #a file with all subject names
                    excluded_subjects = #
                    included_subjects = all_subjects$subjectID[-which(all_subjects$subjectID == excluded_subjects)]

                    parentfolder = '' #the parentfolder where the subject folder/file is
                    restoffilepath = '' #everything after the subject folder/file name

                    trialData = data.frame()
                    subjectData = data.frame()

            .. tab-item:: MatLab

                ::

                    all_subjects = readtable('all_subjects.csv'); % Assuming your file is named 'all_subjects.csv'
                    excluded_subjects = [1, 3, 5]; % Replace with the subject IDs to be excluded
                    included_subjects = all_subjects.subjectID(~ismember(all_subjects.subjectID, excluded_subjects));

                    parentfolder = ''; % Insert your parent folder path
                    restoffilepath = ''; % Insert the rest of the file path

                    trialData = table();
                    subjectData = table();

            .. tab-item:: Python
                
                ::

                    all_subjects = pd.read_csv('all_subjects.csv', sep=';') # Assuming your file is named 'all_subjects.csv'
                    excluded_subjects = [1, 3, 5]  # Replace with the subject IDs to be excluded
                    included_subjects = all_subjects[~all_subjects['subjectID'].isin(excluded_subjects)]['subjectID']
                    
                    parentfolder = ''  # Insert your parent folder path
                    restoffilepath = ''  # Insert the rest of the file path

                    trialData = pd.DataFrame()
                    subjectData = pd.DataFrame()

.. dropdown:: Define the :bdg-success:`Subject` Loop

    .. tab-set::

            .. tab-item:: Plain English

                We're going to start our most superior ``for`` loop which iterates over :bdg-success:`Subjects` included in our analysis. 
                Before we start talking about recovering parameters, let's just make sure that we have our ducks in a row: 
                
                1. We need the data for this :bdg-success:`Subject``
                2. The :bdg-danger:`Decisions` for this :bdg-success:`Subject` need to be in the same order as the :bdg-primary:`Trial` List we use in our Objective Function
                3. We need to determine what is going to be outputted

                .. dropdown:: So what are we starting with in this loop? 
                        
                    A :bdg-success:`Subject`

                .. dropdown:: And what do we want to finish this loop with?

                    :bdg-success:`Free Parameters` for this :bdg-success:`Subject` as well as all of the relevant variables for assessing our model. 
                    Namely, this would be either be the Negative Log-Likelihood or Sum of Squared Errors of our model predictions. 

                    We also want to output any variables we think will be relevant for additional analyses at a trial-level or at a subject-level.

                .. dropdown:: So what do we need to preallocate before this loop starts?

                    An output for the :bdg-success:`Free Parameters` we'll recover, along with any other subject information. 
                    Also, we'll output all trial-by-trial :bdg-success:`Subject` data that will be relevant later.

                    Both of these are already done, nice.

                .. dropdown:: Then, what do we need to compute within this loop?

                    :bdg-success:`Free Parameters`

            .. tab-item:: R

                ::

                    for (i in 1:length(included_subjects)){
                        datafile = paste(parentfolder, included_subjects[i], restoffilepath, sep = '') # produces a character vector 'parentfolder/included_subjects[i]**.filetype'
                        df = read.csv2(datafile)
                        reorder = df$trialsTask.thisIndex + 1

                        #Determine Free Parameters

                        subjectData[i, ] = #to determine
                        trialData[start:end, ] = #to determine
                    }

            .. tab-item:: MatLab

                ::

                    for i = 1:length(included_subjects)
                        datafile = strcat(parentfolder, included_subjects{i}, restoffilepath); % produces a character vector 'parentfolder/included_subjects{i}**.filetype'
                        df = readtable(datafile);
                        reorder = df.trialsTask_thisIndex + 1;

                        % Determine Free Parameters

                        subjectData(i, :) = %to determine
                        trialData(start:end, :) = %to determine
                    end


            .. tab-item:: Python
                
                ::

                    for i in range(len(included_subjects)):
                        datafile = parentfolder + included_subjects[i] + restoffilepath # produces a character vector 'parentfolder/included_subjects[i]**.filetype'
                        df = pd.read_csv(datafile)
                        reorder = df['trialsTask_thisIndex'] + 1

                        # Determine Free Parameters

                        subjectData[i, :] = #to determine
                        trialData[start:end, :] = #to determine


.. dropdown:: Recover :bdg-success:`Free Parameters`

    .. tab-set::

            .. tab-item:: Plain English

                Now, we are going to answer the Determine Free Parameters demand placed on us in the :bdg-success:`Subject` loop, namely to recover :bdg-success:`Free Parameters`.
                We first need to hand our Objective Function the :bdg-success:`Subject`'s data. 
                Then, we need to store our data before we proceed to the next :bdg-success:`Subject`. 

                .. dropdown:: So what are we starting with? 
                        
                    :bdg-danger:`Decisions`, correctly ordered

                .. dropdown:: And what do we want to finish with?

                    A single set of :bdg-success:`Free Parameters`

                .. dropdown:: So what do we need to preallocate?

                    Nothing, we've already got everything we need.

                .. dropdown:: Then, what do we need to compute?

                    We need to get data about what the model actually predicts based on the recovered :bdg-success:`Free Parameters`.

            .. tab-item:: R

                ::

                    for (i in 1:length(included_subjects)){
                        datafile = paste(parentfolder, included_subjects[i], restoffilepath, sep = '') # produces a character vector 'parentfolder/included_subjects[i]**.filetype'
                        df = read.csv2(datafile)
                        reorder = df$trialsTask.thisIndex + 1

                        #Just Added

                        result = fmincon(obj_function,x0 = initial_params, A = NULL, b = NULL, Aeq = NULL, beq = NULL,
                                         lb = lower_bounds, ub = upper_bounds,
                                         decisions = df$Decisions)

                        # Determine Predictions
                    }
                    

            .. tab-item:: MatLab

                ::

                    for i = 1:length(included_subjects)
                        datafile = strcat(parentfolder, included_subjects{i}, restoffilepath); % produces a character vector 'parentfolder/included_subjects{i}**.filetype'
                        df = readtable(datafile);
                        reorder = df.trialsTask_thisIndex + 1;

                        % Just Added

                        options = optimoptions('fmincon', 'Display', 'off');
                        result = fmincon(@obj_function, initial_params, [], [], [], [], lower_bounds, upper_bounds, [], options);
                        
                        % Determine Predictions
                    end


            .. tab-item:: Python
                
                ::

                    for i in range(len(included_subjects)):
                        datafile = parentfolder + included_subjects[i] + restoffilepath  # produces a character vector 'parentfolder/included_subjects[i]**.filetype'
                        df = np.genfromtxt(datafile, delimiter=',', skip_header=1)
                        reorder = df[:, df_header.index('trialsTask_thisIndex')] + 1

                        # Just Added

                        result = fmin_con(obj_function, x0=initial_params, bounds=(lower_bounds, upper_bounds))

                        # Determine Predictions


.. dropdown:: Determine Predicted :bdg-danger:`Decisions` for these :bdg-success:`Free Parameters`

    .. tab-set::

            .. tab-item:: Plain English

                Now, we are going to answer the Determine Predictions demand placed on us.
                We have found the :bdg-success:`Subject`'s :bdg-success:`Free Parameters` so we need to specifically know what it is that our model predicts that they will do.
                In the previous step, we could have cut a corner and gotten the predictions from the closest point we simulated data for. 
                In all likelihood, the model predictions would be indistinguishable from these, but for the sake of being punctual let's get these predictions! 

                .. dropdown:: So what are we starting with? 
                        
                    :bdg-success:`Free Parameters`, :bdg-danger:`Decisions`, and the :bdg-primary:`Trial` Set

                .. dropdown:: And what do we want to finish with?

                    Predicted :bdg-danger:`Decisions` and the Model Error (which we will compute by comparing Predicted-and-Observed :bdg-danger:`Decisions`)

                    A tip here, always name your columns immediately below your loop so that you don't forget what is what!

                .. dropdown:: So what do we need to preallocate?

                    A vector for our predicted :bdg-danger:`Decisions`.

                .. dropdown:: Then, what do we need to compute?

                    Nothing more.

            .. tab-item:: R

                ::

                    for (i in 1:length(included_subjects)){
                        datafile = paste(parentfolder, included_subjects[i], restoffilepath, sep = '') # produces a character vector 'parentfolder/included_subjects[i]**.filetype'
                        df = read.csv2(datafile)
                        reorder = df$trialsTask.thisIndex + 1
                        result = fmincon(obj_function,x0 = initial_params, A = NULL, b = NULL, Aeq = NULL, beq = NULL,
                                         lb = lower_bounds, ub = upper_bounds,
                                         decisions = df$Decisions)

                        #Just Added

                        closestPoint = which(as.numeric(freeParameters[,1]) == as.numeric(round(result$par[1])) & as.numeric(freeParameters[,2]) == as.numeric(round(result$par[2])))
                        df$Prediction = vector('numeric')
                        for (k in 1:length(df$Decisions)){
                            Utility = vector('numeric', length(Choices))
                            for (n in 1:length(Choices)){
                                Utility[n] = utility(parameter1 = results$par[1],
                                                    parameter2 = results$par[2],
                                                    construct1 = construct1(df$IV[k], df$Constant[k], Choices[n]),
                                                    construct2 = construct2(df$IV[k], df$Constant[k], Choices[n])),
                                                    construct3 = construct3(df$IV[k], df$Constant[k], Choices[n])
                            }
                            correct_choice = which(Utility == max(Utility))
                            if (length(correct_choice) > 1){
                                correct_choice = correct_choice[sample(correct_choice, 1)]
                            }
                            df$Prediction[k] = Choices[correct_choice]
                        }

                        model_NLL = -2 * log(sum(dnorm(df$Decision, mean = df$Prediction)))
                        model_SS = sum((df$Decision - df$Prediction)**2)

                        subjectData[i, ] = c(included_subjects[i], result$par[1], result$par[2],  freeParameters$Strategy[closestPoint], model_NLL, modelSS) 
                                            #add any additional subject-level variables; if we have a priori clusters, you can include the strategy like we've done here
                        
                        start = length(subjectData[, 1]) + 1
                        end = start + length(df$Decisions)
                        trialData[start:end, 1] = included_subjects[i]
                        trialData[start:end, 2] = df$IV
                        trialData[start:end, 3] = df$Constant
                        trialData[start:end, 4] = df$Decision
                        trialData[start:end, 5] = df$Prediction
                    }
                    colnames(subjectData) = c('SubjectID', 'Parameter1', 'Parameter2', 'Strategy', 'modelNLL', 'modelSS')
                    colnames(trialData) = c('SubjectID', 'IV', 'Constant', 'Decision', 'Prediction') 

            .. tab-item:: MatLab

                ::

                    for i = 1:length(included_subjects)
                        datafile = strcat(parentfolder, included_subjects{i}, restoffilepath); % produces a character vector 'parentfolder/included_subjects[i]**.filetype'
                        df = readtable(datafile);
                        reorder = df.trialsTask_thisIndex + 1;
                        result = fmincon(@obj_function, initial_params, [], [], [], [], lower_bounds, upper_bounds, df.Decisions);

                        % Just Added

                        closestPoint = find(str2double(freeParameters(:,1)) == round(result(1)) & str2double(freeParameters(:,2)) == round(result(2)));
                        df.Prediction = zeros(size(df.Decisions));
                        for k = 1:length(df.Decisions)
                            Utility = zeros(size(Choices));
                            for n = 1:length(Choices)
                                Utility(n) = utility(result(1), result(2), construct1(df.IV(k), df.Constant(k), Choices(n)), construct2(df.IV(k), df.Constant(k), Choices(n)), construct3(df.IV(k), df.Constant(k), Choices(n)));
                            end
                            correct_choice = find(Utility == max(Utility));
                            if length(correct_choice) > 1
                                correct_choice = correct_choice(randi(length(correct_choice), 1));
                            end
                            df.Prediction(k) = Choices(correct_choice);
                        end

                        model_NLL = -2 * log(sum(normpdf(df.Decision, df.Prediction)));
                        model_SS = sum((df.Decision - df.Prediction).^2);

                        subjectData(i, :) = [included_subjects{i}, result(1), result(2), freeParameters.Strategy(closestPoint), model_NLL, model_SS]; 
                        start = size(subjectData, 1) + 1;
                        end_ = start + length(df.Decisions);
                        trialData(start:end_, 1) = included_subjects{i};
                        trialData(start:end_, 2) = df.IV;
                        trialData(start:end_, 3) = df.Constant;
                        trialData(start:end_, 4) = df.Decision;
                        trialData(start:end_, 5) = df.Prediction;
                    end
                    subjectData.Properties.VariableNames = {'SubjectID', 'Parameter1', 'Parameter2', 'Strategy', 'modelNLL', 'modelSS'};
                    trialData.Properties.VariableNames = {'SubjectID', 'IV', 'Constant', 'Decision', 'Prediction'};


            .. tab-item:: Python
                
                ::

                    for i in range(len(included_subjects)):
                        datafile = parentfolder + included_subjects[i] + restoffilepath  # produces a character vector 'parentfolder/included_subjects[i]**.filetype'
                        df = pd.read_csv(datafile, sep='\t')
                        reorder = df['trialsTask_thisIndex'] + 1
                        result = fmincon(obj_function, x0=initial_params, A=None, b=None, Aeq=None, beq=None, lb=lower_bounds, ub=upper_bounds, decisions=df['Decisions'])

                        # Just Added

                        closestPoint = np.where((freeParameters[:, 0].astype(float) == round(result[0])) & (freeParameters[:, 1].astype(float) == round(result[1])))[0]
                        df['Prediction'] = np.zeros(len(df['Decisions']))
                        for k in range(len(df['Decisions'])):
                            Utility = np.zeros(len(Choices))
                            for n in range(len(Choices)):
                                Utility[n] = utility(result[0], result[1], construct1(df['IV'][k], df['Constant'][k], Choices[n]), construct2(df['IV'][k], df['Constant'][k], Choices[n]), construct3(df['IV'][k], df['Constant'][k], Choices[n]))
                            correct_choice = np.where(Utility == max(Utility))[0]
                            if len(correct_choice) > 1:
                                correct_choice = np.random.choice(correct_choice, 1)
                            df['Prediction'][k] = Choices[correct_choice[0]]

                        model_NLL = -2 * np.log(np.sum(norm.pdf(df['Decision'], df['Prediction'])))
                        model_SS = np.sum((df['Decision'] - df['Prediction'])**2)

                        subjectData[i, :] = [included_subjects[i], result[0], result[1], freeParameters['Strategy'][closestPoint[0]], model_NLL, model_SS]
                        start = subjectData.shape[0] + 1
                        end_ = start + len(df['Decisions'])
                        trialData[start:end_, 0] = included_subjects[i]
                        trialData[start:end_, 1] = df['IV']
                        trialData[start:end_, 2] = df['Constant']
                        trialData[start:end_, 3] = df['Decision']
                        trialData[start:end_, 4] = df['Prediction']

                    subjectData.columns = ['SubjectID', 'Parameter1', 'Parameter2', 'Strategy', 'modelNLL', 'modelSS']
                    trialData.columns = ['SubjectID', 'IV', 'Constant', 'Decision', 'Prediction']


Tutorials
==========

Tutorial 1 - van Baar, Chang, & Sanfey, 2019
----------------------

.. dropdown:: Preallocating and Defining Functions
.. dropdown:: Define the :bdg-success:`Subject` Loop
.. dropdown:: Recover :bdg-success:`Free Parameters`
.. dropdown:: Determine Predicted :bdg-danger:`Decisions` for these :bdg-success:`Free Parameters`

Tutorial 2 - Galvan & Sanfey, 2024
-------------------

.. dropdown:: Preallocating and Defining Functions
.. dropdown:: Define the :bdg-success:`Subject` Loop
.. dropdown:: Recover :bdg-success:`Free Parameters`
.. dropdown:: Determine Predicted :bdg-danger:`Decisions` for these :bdg-success:`Free Parameters`

Tutorial 3 - Crockett et al., 2014
-------------------

.. dropdown:: Preallocating and Defining Functions
.. dropdown:: Define the :bdg-success:`Subject` Loop
.. dropdown:: Recover :bdg-success:`Free Parameters`
.. dropdown:: Determine Predicted :bdg-danger:`Decisions` for these :bdg-success:`Free Parameters`